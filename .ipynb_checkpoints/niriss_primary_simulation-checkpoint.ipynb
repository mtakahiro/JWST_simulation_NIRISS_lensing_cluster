{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowded field photometry --- 1a. NIRISS imaging & WFSS simulation\n",
    "\n",
    "This notebook demonstrates how to create JWST data by using [MIRAGE](https://mirage-data-simulator.readthedocs.io/en/latest/).\n",
    "This is one of series of notebooks that focus on crwoded field photometry (see other notebooks in the directory).\n",
    "\n",
    "\n",
    "This notebook will demonstrate how to create NIRISS WFSS and direct image simulation. It will require the following input files;\n",
    "1. APT output files (.xml and .pointing) that specify the observation\n",
    "2. A source catalog that lists source properties (magnitude/morphology...), taken from HST.\n",
    "\n",
    "Users may also provide their catalog/apt files, to create own scenes, but may need to allocate columns for physical parameters.\n",
    "\n",
    "\n",
    "## To Do:\n",
    "- 1.Read input catalogs\n",
    "- 2.Generate two Mirage friendly source catalogs (one for point source, and the other for extended).\n",
    "- 3.Generate a set of yaml files, setup files for Mirage.\n",
    "- 4.Run simulation for NIRISS direct images and WFSS.\n",
    "\n",
    "*Reduction of these generated raw data will be demonstrated in another notebook.\n",
    "\n",
    "### Requirement:\n",
    "- Mirage environment. [see here](https://mirage-data-simulator.readthedocs.io/en/latest/install.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "# It may be helpful to set these within your .bashrc or .cshrc file, so that CRDS will\n",
    "# know where to look for reference files during future runs of the JWST calibration\n",
    "# pipeline.\n",
    "\n",
    "import os\n",
    "\n",
    "# if you are in the institute network, read here;\n",
    "# https://mirage-data-simulator.readthedocs.io/en/latest/reference_files.html\n",
    "# Otherwise, you need to download to your local directory.\n",
    "\n",
    "path_mirage = '/path/into/which/files/are/downlaoded/'\n",
    "\n",
    "if os.path.exists(path_mirage):\n",
    "    os.environ[\"MIRAGE_DATA\"] = path_mirage\n",
    "else:\n",
    "    from mirage.reference_files import downloader\n",
    "    download_path = path_mirage\n",
    "    downloader.download_reffiles(download_path, instrument='all', dark_type='linearized', skip_darks=False, skip_cosmic_rays=False, skip_psfs=False, skip_grism=False)\n",
    "    os.environ[\"MIRAGE_DATA\"] = path_mirage\n",
    "\n",
    "os.environ[\"CRDS_PATH\"] = os.path.join(os.path.expandvars('$HOME'), \"crds_cache\")\n",
    "os.environ[\"CDRS_SERVER_URL\"] = \"https://jwst-cdrs.stsci.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pkg_resources\n",
    "import yaml\n",
    "\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "from astropy.visualization import simple_norm, imshow_norm\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mirage import imaging_simulator\n",
    "from mirage import wfss_simulator\n",
    "from mirage.utils.constants import FLAMBDA_CGS_UNITS, FLAMBDA_MKS_UNITS, FNU_CGS_UNITS \n",
    "from mirage.yaml import yaml_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mirage\n",
    "import astropy\n",
    "\n",
    "print('mirage ver:',mirage.__version__)\n",
    "print('astropy ver:',astropy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='yaml_from_apt'></a>\n",
    "## Create a series of yaml files from [APT](https://jwst-docs.stsci.edu/display/JPP/JWST+Astronomers+Proposal+Tool+Overview)\n",
    "\n",
    "To set Mirage up for your observation designed in APT, you need to get .xml and .pointing files out of your APT file and provide them to Mirage.\n",
    "You can get these files from APT's tool bar ([File]->[Export]).\n",
    "\n",
    "As an example, observation here is taken from [GLASS-ERS](http://www.stsci.edu/jwst/observing-programs/approved-ers-programs/program-1324). Some modifications were added.\n",
    "\n",
    "Let's download these files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import urllib.request\n",
    "boxlink = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/NIRISS_lensing_cluster/files.zip'\n",
    "boxfile = './files.zip'\n",
    "DIR_DATA = './files/'\n",
    "\n",
    "if not os.path.exists(boxfile):\n",
    "    urllib.request.urlretrieve(boxlink, boxfile)\n",
    "    zf = zipfile.ZipFile(boxfile, 'r')\n",
    "    zf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Input files from APT\n",
    "#\n",
    "# These can be obtained from a tab, [File]->[Export], in APT.\n",
    "xml_file      = '%sA2744_example_nis.xml'%DIR_DATA\n",
    "pointing_file = '%sA2744_example_nis.pointing'%DIR_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These following are some misc params for Mirage.\n",
    "\n",
    "# Set reference file values. \n",
    "# Setting to 'crds_full_name' will search for and download needed\n",
    "# calibration reference files (commonly referred to as CRDS reference files) when\n",
    "# the yaml_generator is run. \n",
    "# \n",
    "# Setting to 'crds' will put placeholders in the yaml files and save the downloading\n",
    "# for when the simulated images are created.\n",
    "reffile_defaults = 'crds'\n",
    "\n",
    "# Optionally set the cosmic ray library and rate\n",
    "cosmic_rays = {'library': 'SUNMAX', 'scale': 1.0}\n",
    "\n",
    "# Optionally set the observation date to use for the data. Note that this information\n",
    "# is placed in the headers of the output files, but not used by Mirage in any way.\n",
    "dates = '2022-07-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally set the background signal rates to be used\n",
    "# As in Cami's note, this may not work.\n",
    "background = 'low' # 'medium', 'high', or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally set the telescope roll angle (PAV3) for the observations\n",
    "# This can be checked in APT's Aladin function.\n",
    "pav3 = 230 #12.5 + 45."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the data reduction state of the Mirage outputs.\n",
    "Options are 'raw', 'linear', or 'linear, raw'. \n",
    "\n",
    "If 'raw' is specified, the output is a completely uncalibrated file, with a filename ending in \"uncal.fits\"\n",
    "\n",
    "If 'linear' is specified, the output is a file with linearized signals, ending in \"linear.fits\". This is equivalent to having been run through the dq_init, saturation flagging, superbias subtraction, reference pixel subtraction, and non-linearity correction steps of the calibration pipeline. Note that this product does not include dark current subtraction.\n",
    "\n",
    "If 'linear, raw', both outputs are saved.\n",
    "\n",
    "In order to fully process the Mirage output with the default steps used by the pipeline, it would be best to use the 'raw' output and run the entire calibration pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = 'raw' # 'linear, raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Make a catalog based on a real field. \n",
    "\n",
    "Here we use a set of catalogs from [Morishita et al. (2016)](https://ui.adsabs.harvard.edu/abs/2017ApJ...835..254M/abstract), on Hubble Frontier Fields cluster, Abell2744.\n",
    "Catalogs are located in the current directory.\n",
    "\n",
    "- input_01.cat : Flux catalog for 7 HST filters. We will use some of them to provide source fluxes to Mirage.\n",
    "- f160w_01.cat : SExtractor catalog for the same targets. We will use morphological parameters.\n",
    "\n",
    "Users may also provide their own catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target ID for the field;\n",
    "FLD    = 'abell2744clu'\n",
    "FLDID  = '01'\n",
    "\n",
    "# Input catalog for flux infos\n",
    "input_phot = '%sinput_%s.cat'%(DIR_DATA,FLDID)\n",
    "magzp = 25.0 # Magnitude zeropoint of fluxes in the input catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import ascii\n",
    "t = ascii.read(input_phot)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, read Sextractor catalog;\n",
    "pixscale = 0.06 # arcsec/pixel\n",
    "\n",
    "input_sext = '%sf160w_%s.cat'%(DIR_DATA,FLDID)\n",
    "ts = ascii.read(input_sext)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get morphology params;\n",
    "idsext = ts['NUMBER']\n",
    "radius = ts['FLUX_RADIUS']*pixscale # in arcsec\n",
    "elong  = ts['ELONGATION'] # = a/b\n",
    "\n",
    "pa         = 90. - ts['THETA_IMAGE'] # Theta_mirage = 90 - Theta_Sext\n",
    "pa += pav3 + pav3 # Doe to a conflict with Mirage.\n",
    "magauto    = ts['MAG_AUTO']\n",
    "class_star = ts['CLASS_STAR']\n",
    "ellip      = 1. - 1/elong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the SExtractor catalog does not provide Sersic index;\n",
    "# Set those bright, but extended object to n=4.\n",
    "ser = radius * 0 + 1.0\n",
    "con_ser = (magauto<20) & (class_star<0.9)\n",
    "ser[con_ser] = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now, just magnitude and source morphology are simulated.\n",
    "#### One may also want to include redshift, to simulate SEDs for those not listed in the flux catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Then redshift information\n",
    "# This is for redshift;\n",
    "'''\n",
    "input_eazy = './files/photz_%s.zout'%(FLDID)\n",
    "ez = ascii.read(input_eazy)\n",
    "ez\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary infos;\n",
    "id  = t['id']\n",
    "ra  = ts['X_WORLD']\n",
    "dec = ts['Y_WORLD']\n",
    "#red = ez['z_m1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage flux column;\n",
    "# This corresponds to photometric catalog;\n",
    "filt  = ['F105W','F125W','F140W','F160W','F435W','F606W','F814W']\n",
    "efilt = ['202','203','204','205','1','4','6'] # Corresponding column number in t.\n",
    "\n",
    "flux = np.zeros((len(filt),len(id)),dtype='float32')\n",
    "eflux= np.zeros((len(filt),len(id)),dtype='float32')\n",
    "for ff in range(len(filt)):\n",
    "    flux[ff,:]  = t['F%s'%(efilt[ff])]\n",
    "    eflux[ff,:] = t['E%s'%(efilt[ff])]\n",
    "\n",
    "# Define magnitude\n",
    "mag160 = -2.5 * np.log10(flux[3,:]) + magzp\n",
    "\n",
    "# Mask those with negative flux;\n",
    "con    = (flux[3,:]<=0)\n",
    "mag160[con] = 99\n",
    "mag160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Write source properties in a catalog that is compatible with Mirage\n",
    "Here, we are making a Mirage-friendly catalog out of the two table above.\n",
    "\n",
    "For now, let's stick with a simple case, by pretending input magnitudes corresponds JWST magnitudes.\n",
    "- HST F160W -> JWST F200W\n",
    "- F140W -> F150W\n",
    "- F105W -> F115W\n",
    "- F814W -> F090W\n",
    "\n",
    "One can also use ground-based K data for F200W, or SED fitting results extrapolated to F200W.\n",
    "See also [this notebook](https://github.com/spacetelescope/dat_pyinthesky/tree/master/jdat_notebooks/NIRCam_photometry) for making use of Jades simulation catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write into two files;\n",
    "# 1. extended source catalog\n",
    "# 2. point source catalog\n",
    "file_extend_name = './sources_extend_%s.cat'%(FLDID)\n",
    "file_point_name  = './sources_point_%s.cat'%(FLDID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for index info that directs us to filters we need.\n",
    "ii105 = np.where(np.asarray(filt[:]) == 'F105W')[0][0]\n",
    "ii140 = np.where(np.asarray(filt[:]) == 'F140W')[0][0]\n",
    "ii160 = np.where(np.asarray(filt[:]) == 'F160W')[0][0]\n",
    "ii814 = np.where(np.asarray(filt[:]) == 'F814W')[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips : \n",
    "If you are providing more than one catalog, then you need to (re-)assign IDs for the objects in the catalogs other than first, so none of them has smaller ID (nor overlapping ID) in the catalog beforehand.\n",
    "\n",
    "The priority of catalog is in the following order; point source, then galaxies, then extended. [See here if you like](https://github.com/spacetelescope/mirage/issues/476)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start writing;\n",
    "fw = open(file_point_name,'w')\n",
    "fw.write('# position_RA_Dec\\n# abmag\\n#\\n#\\n')\n",
    "# Let's approximate WFC3IR F140W to NIRISS F150W\n",
    "# Let's approximate WFC3IR F160W to NIRISS F200W\n",
    "# Future work will extract magnitude from the SED fitting result the corresponding filters.\n",
    "fw.write('index   x_or_RA      y_or_Dec    niriss_f115w_magnitude    niriss_f150w_magnitude    niriss_f090w_magnitude    niriss_f200w_magnitude\\n')\n",
    "\n",
    "# Extended source catalog; \n",
    "# see https://mirage-data-simulator.readthedocs.io/en/latest/catalogs.html#extended-obj for more.\n",
    "fw2 = open(file_extend_name,'w')\n",
    "fw2.write('# position_RA_Dec\\n# abmag\\n#\\n#\\n')\n",
    "fw2.write('index   x_or_RA      y_or_Dec    radius    ellipticity    pos_angle       sersic_index     niriss_f115w_magnitude    niriss_f150w_magnitude    niriss_f090w_magnitude    niriss_f200w_magnitude\\n')\n",
    "\n",
    "# For the sake of test, only bright sources;\n",
    "mag_lim = 20 #\n",
    "filt_targ = 'F200W' # Targer filter of this simulation. \n",
    "\n",
    "# Adding a constant to IDs in the second catalog (i.e. Tips above.);\n",
    "nrand = 10000\n",
    "\n",
    "for ii in range(len(id)):\n",
    "    # Check you have positive flux;\n",
    "    if flux[ii140,ii]>0:\n",
    "        mag_140 = -2.5 * np.log10(flux[ii140,ii])+magzp\n",
    "    else:\n",
    "        mag_140 = 99\n",
    "\n",
    "    if flux[ii105,ii]>0:\n",
    "        mag_105 = -2.5 * np.log10(flux[ii105,ii])+magzp\n",
    "    else:\n",
    "        mag_105 = 99\n",
    "\n",
    "    if flux[ii160,ii]>0:\n",
    "        mag_160 = -2.5 * np.log10(flux[ii160,ii])+magzp\n",
    "    else:\n",
    "        mag_160 = 99\n",
    "\n",
    "    if flux[ii814,ii]>0:\n",
    "        mag_814 = -2.5 * np.log10(flux[ii814,ii])+magzp\n",
    "    else:\n",
    "        mag_814 = 99\n",
    "\n",
    "    # As mirage cannot handle very faint objects for now...\n",
    "    if mag_160<mag_lim:\n",
    "        iisext = np.where(id[ii] == idsext[:])\n",
    "        if class_star[ii] > 0.90: # for point sources\n",
    "            fw.write('%d %.8f %.8f %.3f %.3f %.3f %.3f\\n'%(id[ii],ra[iisext],dec[iisext],mag_105,mag_140,mag_814,mag_160))\n",
    "        else: # for extended source\n",
    "            fw2.write('%d %.8f %.8f %.3f %.3f %.3f %.3f %.3f %.3f %.3f %.3f\\n'%(id[ii]+nrand,ra[iisext],dec[iisext],radius[iisext],ellip[iisext],pa[iisext],ser[iisext],mag_105,mag_140,mag_814,mag_160))\n",
    "\n",
    "fw.close()\n",
    "fw2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign these catalogs to Mirage;\n",
    "# How to assign;\n",
    "# -> See here; https://mirage-data-simulator.readthedocs.io/en/latest/yaml_generator.html\n",
    "catalogs = {'point_source': file_point_name,'galaxy': file_extend_name}\n",
    "catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Yaml file generator\n",
    "Create a series of Mirage input yaml files\n",
    "yaml file is a sort of setup file for Mirage to execute its simulation.\n",
    "It includes all infomation specified above (background, observing time, source catalog, exposure time...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yaml output directory;\n",
    "yaml_output_dir = './yaml/'\n",
    "if not os.path.exists(yaml_output_dir):\n",
    "    os.mkdir(yaml_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, set a simulation output directory;\n",
    "simulations_output_dir = './output/'\n",
    "if not os.path.exists(simulations_output_dir):\n",
    "    os.mkdir(simulations_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the yaml generator\n",
    "yam = yaml_generator.SimInput(input_xml=xml_file, pointing_file=pointing_file,\n",
    "                              catalogs=catalogs, cosmic_rays=cosmic_rays,\n",
    "                              background=background,roll_angle=pav3,\n",
    "                              dates=dates, reffile_defaults=reffile_defaults,\n",
    "                              verbose=True, output_dir=yaml_output_dir,\n",
    "                              simdata_output_dir=simulations_output_dir,\n",
    "                              datatype=datatype)\n",
    "yam.create_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look to see which yaml files are for WFSS and which are imaging.\n",
    "\n",
    "Note that NIRCAM parallel imaging is also included, as it is included in APT, but these will be simulated in another notebook, to avoid confusion.\n",
    "\n",
    "Here, we just focus on NIRISS images and WFSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_files = glob(os.path.join(yaml_output_dir,\"jw*.yaml\"))\n",
    "\n",
    "yaml_WFSS_files = []\n",
    "yaml_NIRISS_imaging_files = []\n",
    "\n",
    "for f in yaml_files:\n",
    "    my_dict = yaml.safe_load(open(f))\n",
    "    if my_dict[\"Inst\"][\"mode\"]==\"wfss\" and my_dict[\"Readout\"][\"pupil\"]==filt_targ:\n",
    "        yaml_WFSS_files.append(f)\n",
    "    if my_dict[\"Inst\"][\"mode\"]==\"imaging\" and my_dict['Inst']['instrument']=='NIRISS' and my_dict[\"Readout\"][\"pupil\"]==filt_targ:\n",
    "        yaml_NIRISS_imaging_files.append(f)\n",
    "    \n",
    "print(\"WFSS files:\",len(yaml_WFSS_files))\n",
    "print(\"Imaging files:\",len(yaml_NIRISS_imaging_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output yaml file contains details on the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import Loader, Dumper\n",
    "with open(yaml_NIRISS_imaging_files[0], 'r') as infile:\n",
    "    parameters = yaml.load(infile, Loader=Loader)\n",
    "    \n",
    "for key in parameters:\n",
    "    for level2_key in parameters[key]:\n",
    "        print('{}: {}: {}'.format(key, level2_key, parameters[key][level2_key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Direct Images\n",
    "#### First, we create imaging simulation. WFSS will follow later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we provide a single yaml file as input. In this case, Mirage will create a direct (undispersed) seed image for the yaml file. For each source, Mirage will construct a continuum spectrum by either:\n",
    "\n",
    "1. Interpolating the filtered magnitudes in the catalogs listed in the yaml file\n",
    "2. If only a single filter's magnitude is given, Mirage will extrapolate to produce a flat continuum\n",
    "\n",
    "This continuum spectrum will then be placed in the dispersed seed image, which will then be combined with a dark current exposure in order to create the final simulated exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in yaml_NIRISS_imaging_files[:]:\n",
    "    img_sim = imaging_simulator.ImgSim()\n",
    "    img_sim.paramfile = file\n",
    "    img_sim.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Seed image;\n",
    "checkid = yaml_NIRISS_imaging_files[0].split('/')[-1].replace('.yaml','') #'jw00042001001_01101_00012_nis'\n",
    "\n",
    "final_file = os.path.join(simulations_output_dir, '%s_uncal_CLEAR_%s_final_seed_image.fits'%(checkid,filt_targ))\n",
    "with fits.open(final_file) as hdulist:\n",
    "    data = hdulist[1].data\n",
    "    hdulist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "norm = simple_norm(data[:, :], stretch='log', min_cut=0, max_cut=100)\n",
    "cax = ax.imshow(data[:, :], norm=norm)\n",
    "cbar = fig.colorbar(cax)\n",
    "plt.title('This is a seed image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with the real F160W image, if you like;\n",
    "file_f160w = 'hlsp_frontier_hst_wfc3-60mas_abell2744_f160w_v1.0_drz.fits'\n",
    "if not os.path.exists(file_f160w):\n",
    "    link_hst = 'https://archive.stsci.edu/pub/hlsp/frontier/abell2744/images/hst/v1.0-epoch1/%s'%file_f160w\n",
    "    urllib.request.urlretrieve(link_hst, file_f160w)\n",
    "\n",
    "with fits.open(file_f160w) as hdulist:\n",
    "    data_real = hdulist[0].data\n",
    "    hdulist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "fig = plt.figure(figsize=(15.,10.))\n",
    "fig.subplots_adjust(top=0.98, bottom=0.16, left=0.1, right=0.99, hspace=0.15, wspace=0.25)\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "norm = simple_norm(data[:,:], stretch='log', min_cut=0, max_cut=10)\n",
    "rotated_img = ndimage.rotate(data[:,:], -pav3)\n",
    "\n",
    "cax = ax1.imshow(rotated_img, norm=norm)\n",
    "\n",
    "norm = simple_norm(data_real[1200:3800, 1200:3800], stretch='log', min_cut=0, max_cut=10)\n",
    "cax = ax2.imshow(data_real[1200:3800, 1200:3800], norm=norm)\n",
    "cbar = fig.colorbar(cax)\n",
    "ax1.set_title('Mirage')\n",
    "ax2.set_title('HST F160W')\n",
    "plt.savefig('01_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also check uncal image, i.e. simulated images with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_file = os.path.join(simulations_output_dir, '%s_uncal.fits'%checkid)\n",
    "with fits.open(final_file) as hdulist:\n",
    "    data = hdulist['SCI'].data\n",
    "    hdulist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "norm = simple_norm(data[0, -1, :, :], stretch='log', min_cut=5000, max_cut=50000)\n",
    "cax = ax.imshow(data[0, -1, :, :], norm=norm)\n",
    "cbar = fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run WFSS simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first prepare SED for each source. \n",
    "\n",
    "This can be done either by 1. using SED fitting result from HST photometry, 2. simply assume a uniform SED for all sources, or 3. let Mirage extraporate from input catalog.\n",
    "\n",
    "Here, just for simplicity, I let Mirage interporate SED (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_output_dir = './yaml/' #TEST_DATA_DIRECTORY\n",
    "simulations_output_dir = './output/' #TEST_DATA_DIRECTORY\n",
    "yaml_files = glob(os.path.join(yaml_output_dir,\"jw*.yaml\"))\n",
    "\n",
    "yaml_WFSS_files = []\n",
    "yaml_NIRISS_imaging_files = []\n",
    "for f in yaml_files:\n",
    "    my_dict = yaml.safe_load(open(f))\n",
    "    if my_dict[\"Inst\"][\"mode\"]==\"wfss\" and my_dict[\"Readout\"][\"pupil\"]==filt_targ:\n",
    "        yaml_WFSS_files.append(f)\n",
    "    if my_dict[\"Inst\"][\"mode\"]==\"imaging\" and my_dict['Inst']['instrument']=='NIRISS' and my_dict[\"Readout\"][\"pupil\"]==filt_targ:\n",
    "        yaml_NIRISS_imaging_files.append(f)\n",
    "    \n",
    "print(\"WFSS files:\",len(yaml_WFSS_files))\n",
    "print(\"Imaging files:\",len(yaml_NIRISS_imaging_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run for wfss --- it takes time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mirage import wfss_simulator\n",
    "\n",
    "#os.system('rm source_sed_file_from_sources_point_01.hdf5')\n",
    "for file in yaml_WFSS_files[:]:\n",
    "    m = wfss_simulator.WFSSSim(file, override_dark=None, save_dispersed_seed=True,\n",
    "                               extrapolate_SED=None, disp_seed_filename=None, source_stamps_file=None,\n",
    "                               SED_file=None, SED_normalizing_catalog_column=None, SED_dict=None,\n",
    "                               create_continuum_seds=True) #, disp_seed_filename=disp_seed_image\n",
    "\n",
    "    m.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dispersed image;\n",
    "checkid = yaml_WFSS_files[0].split('/')[-1].replace('.yaml','') #'jw00042001001_01101_00012_nis'\n",
    "\n",
    "final_file = os.path.join(simulations_output_dir, '%s_uncal_dispersed_seed_image.fits'%(checkid))\n",
    "with fits.open(final_file) as hdulist:\n",
    "    data_wfss = hdulist[1].data\n",
    "    hdulist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "fig = plt.figure(figsize=(20.,10.))\n",
    "fig.subplots_adjust(top=0.98, bottom=0.16, left=0.1, right=0.99, hspace=0.15, wspace=0.25)\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "norm = simple_norm(data[:,:], stretch='log', min_cut=0, max_cut=10)\n",
    "rotated_img = ndimage.rotate(data[:,:], -pav3)\n",
    "ax2.imshow(rotated_img, norm=norm, origin='lower')\n",
    "\n",
    "norm = simple_norm(data_wfss[:,:], stretch='log', min_cut=0, max_cut=10)\n",
    "rotated_wfss = ndimage.rotate(data_wfss[:,:], -pav3)\n",
    "ax3.imshow(rotated_wfss, norm=norm, origin='lower')\n",
    "\n",
    "norm = simple_norm(data_real[1200:3800, 1200:3800], stretch='log', min_cut=0, max_cut=10)\n",
    "cax = ax1.imshow(data_real[1200:3800, 1200:3800], norm=norm, origin='lower')\n",
    "#cbar = fig.colorbar(cax)\n",
    "\n",
    "ax1.set_title('HST F160W')\n",
    "ax2.set_title('Mirage Direct Image (%s)'%filt_targ)\n",
    "ax3.set_title('Mirage Dispersed Image (%s+G150)'%filt_targ)\n",
    "\n",
    "plt.savefig('01_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIRCam parallel imaging is in another notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
